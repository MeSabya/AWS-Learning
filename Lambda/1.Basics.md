## what is serverless ? 

Serverless does not mean there are no servers , it only means we just don't manage /provision/see them.

serverless pioneered by AWS lambda but now also includes anything thats managed.

initially serverless == Faas (Function as a service)

![image](https://user-images.githubusercontent.com/33947539/163801540-48e2e0d9-bcc4-4e91-b754-b6fcaf8be77d.png)


## What is Serverless Compute ?

>**Serverless compute is a cloud computing execution model in which the AWS Cloud acts as the server and dynamically manages the allocation of machine resources.**

- AWS Lambda is the AWS serverless compute platform that enables you to run code without provisioning or managing servers. 
- With AWS Lambda, you can run code for nearly any type of application or backend service — with zero administration
- Only upload your code, and AWS Lambda performs all the tasks you require to run and scale your code with high availability.

👉 **AWS Lambda is sometimes referred to as a function-as-a-service (FaaS)**

AWS Lambda executes code whenever the function is triggered, and no Amazon Elastic Compute Cloud (Amazon EC2) instances need to be spun up in your infrastructure.

![image](https://user-images.githubusercontent.com/33947539/163801781-99c3290b-affe-451c-9005-31d273fe8d6f.png)

### Okay, but what do your functions do?

Well, at a fundamental level, your functions process events.
Events can come from all sorts of places.
Here’s one example.
A user makes a request to your API (managed by AWS API Gateway).
That particular endpoint is mapped to a Lambda function.
The users calls the endpoint, the Lambda functions gets invoked. It can, in turn, invoke another function.
It could also:
- write to a database
- call another AWS service (e.g. send a notification through AWS SNS)
- return a response (e.g. some text content)

![image](https://user-images.githubusercontent.com/33947539/151407055-47100039-082e-4834-94ce-03781b1e008e.png)

#### Functions in practice

**Example1:**

A user uploads a new image to S3 (which is AWS’s simple storage solutions)).
That upload triggers a Lambda function, which creates a thumbnail version of the image.
After creating the thumbnail, the Lambda function does two things:
1. Uploads the thumbnail to S3
2. Writes the metadata of the image to your database
Boom. Simple image transformation.

![image](https://user-images.githubusercontent.com/33947539/151407181-0fc0a143-2c3b-4d1c-8904-15c7be8bd63f.png)

**Example2**:

![image](https://user-images.githubusercontent.com/33947539/163802876-8ae70fd8-f36c-45a5-af45-b3ce09f49c8c.png)


### How are functions invoked?
Lambda functions are triggered

👉 **synchronously** It means we are waiting for the results and results are returned right away. Done via the AWS Cli, API Gateway, Aplication Load balancer. 

![image](https://user-images.githubusercontent.com/33947539/163806245-79bc9e33-92df-411e-a101-dd124362e61f.png)

👉 **asynchronously** by the other AWS services (File uploads to Amazon AWS S3 buckets, updates to Amazon DynamoDB tables, data in Amazon Kinesis Streams, etc.),

👉 via **event source mappings** (Lambda resource that reads from an event source and invokes a Lambda function) compatible with Amazon DynamoDB, Amazon Kinesis, Amazon MQ, Amazon Managed Streaming for Apache Kafka, self-managed Apache Kafka and Amazon Simple Queue Service.


## Advantages of lambda

👉 AWS provisions and manages the infrastructure your Lambda functions run on, scales the instances to handle times of excessive load, and implements proper logging and error handling.

👉 AWS allows you to run your Lambda function simultaneously with other Lambda functions; meaning, you won’t need to worry about clogged up queues. Not only that, multiple instances of the same Lambda function can be provisioned and run at the same time. Both advantages ensures that no matter how much load your application is under, Lambda will be able to handle it.

👉 you only pay for what you need, AWS charges you for the number of requests your Lambda functions recieve and the time it takes to execute those requests per 100ms

## Disadvantages of AWS Lambda
limitations are the following:

👉 Functions will timeout after 15 minutes.

👉 The amount of RAM available ranges from 128MB to 3008MB with a 64MB increment between each option.

👉 The Lambda code should not exceed 250mb in size, and the zipped version should be no larger than 50mb

👉 Lambda functions are not always the best option when they are heavily invoked. EC2 or Elastic Beanstalk might be good alternatives.

👉 There is a limit of 1,000 requests that can run concurrently, any request above this limit will be throttled and will need to wait for other functions to finish running.

##  How lambda works — Containers creation and recycling

👉*Each lambda function is executed in a container that provides an isolated execution environment*. 
When a function is executed for the first time, a new container with the appropriate resources will be created to execute it, and the code for the function will be loaded into the container. This happens every time the function’s code is updated or when a previously created container is destroyed.


👉 Although AWS will reuse a container when one is available, after some time this container is destroyed. There is no documentation that describe when a container is destroyed nor what event can trigger its destruction. We must keep in mind that Lambda function should be stateless and we should accept that a container could live few minutes or few seconds.

>**TAKEAWAY**: Lambda need to create an isolated container to execute your code. This container can be destroyed at anytime. Make sure your function’s code is stateless.

**A Lambda function consists of 3 or 4 parts:** 

      1. the handler function, 
      2. the event object, 
      3. the context object and 
      4. in some cases a callback function.


- **The event object** contains data that was sent when the function’s event was triggered, this includes information such as the request body and the uri; 
- The context object contains runtime information such as the function name, function version and log group. 
- The callback function is only passed through to synchronous handlers and it takes two arguments: an error and a response. 

>**Once the Lambda function is created and pushed up to AWS, it is compressed along with its dependencies and stored in an S3 bucket.**

## How do I keep track of my changing functions?
👉 **Lambda functions are versioned and aliased.**

This makes updating safe and easy.

So let’s say you make a Lambda function. It’s on version 1 (v1).
You create an endpoint in AWS API Gateway. Let’s call it /imageupload.
You create an alias for v1 of your function, and name it prod.
You map /imageupload to point to prod. When a user makes a request to /imageupload, the v1 Lambda function is invoked.

![image](https://user-images.githubusercontent.com/33947539/151411367-5036fcfa-481c-474a-9bd9-208e1d7a68ec.png)

But then it’s time to update your function. You upload a new version to Lambda. That’s v2.
You alias v2 and name it test.
The prod alias is still pointing to v1. Users are still ONLY interacting with v1.

![image](https://user-images.githubusercontent.com/33947539/151411497-87da7879-f9f3-472d-b4c4-27984aa5e8b0.png)

You can test v2 thoroughly, and when you’re happy, you point the prod alias to v2.
You can also do partial allocation, like routing 60% of traffic to prod to v1, 40% to v2… and then slowly ramp up v2. This is the safest approach.

## Resilience

👉 **AWS runs your Lambda functions in multiple availability zones, this ensures that your functions are not impacted if a single zone is down; **
the same cannot be said for services such as EC2 where this behaviour must be set by the developer. 

With Lambda, developers have the ability to set reserved concurrency for a particular function which ensures that it can always scale to (but not exceed past) a set number of concurrent invocations despite the number of requests other functions are consuming — note that AWS will still adhere to the upper limit of 1,000 requests, which means requests for other functions will be throttled.

## Layers are great

Lambda function can pull in additional code and content in the form of layers. From AWS docs: “A layer is a ZIP archive that contains libraries, a custom runtime, or other dependencies. With layers, you can use libraries in your function without needing to include them in your deployment package.”

👉**Simply put, a lambda layer is a piece of code that can be reused in other lambda functions.** 

👉 The main advantages of layers are, in my opinion:

- It helps you keep your Lambda deployment package under 3MB, the threshold to be able to edit your code in the AWS console.
- It helps you reuse pieces of code and python packages (when using python) that are not available right out the box, such as pandas or numpy.
- Finally, it helps you write readable and clean Lambda functions with reduced operational errors that could occur during installation of dependencies.

>**TAKEAWAY**: Use Lambda layers as much as possible to keep your deployment package small and to stay under the 3MB threshold to be able to edit your code in the AWS console.

## Cold start Problem 

This happens because if your Lambda is not already running, AWS needs to deploy your code and spin up a new container before the request can begin. This can mean a request takes much longer to execute, and only when the container is ready can your lambda start running.

The fact of the matter is that cold starts are a necessary byproduct of the scalability of serverless. Cold starts reflect the AWS Lambda startup time required to “warm up” containers before functions become operational.

🤔 *You may think that if this cold start is only for the first request there is nothing to be worried about ??*

Unfortunately, this is not the case. AWS keeps containers up for a specific time, which seems like 45 minutes today but is prone to change. If the distribution of your function invocation is sparse, you are more open to cold starts. Moreover, if your function is experiencing concurrent invocations, AWS will initialize containers concurrently. It is inevitable that you will catch cold starts at all those containers at the same time. Nightmare, right? Although it is easy to start with and extremely cheap, you cannot lean on this kind of architecture without precautions.





